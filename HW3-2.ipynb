{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python for Research Homework: Week 3, Case Study 2\n",
    "\n",
    "In this case study, we will find and plot the distribution of word frequencies for each translation of Hamlet.  Perhaps the distribution of word frequencies of Hamlet depends on the translation --- let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS CODE!\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def count_words_fast(text):\n",
    "    text = text.lower()\n",
    "    skips = [\".\", \",\", \";\", \":\", \"'\", '\"', \"\\n\", \"!\", \"?\", \"(\", \")\"]\n",
    "    for ch in skips:\n",
    "        text = text.replace(ch, \"\")\n",
    "    word_counts = Counter(text.split(\" \"))\n",
    "    return word_counts\n",
    "\n",
    "def read_book(title_path):\n",
    "    text   = pd.read_csv(title_path, sep = \"\\n\", engine='python', encoding=\"utf8\")\n",
    "    text = text.to_string(index = False)\n",
    "    return text\n",
    "\n",
    "def word_stats(word_counts):\n",
    "    num_unique = len(word_counts)\n",
    "    counts = word_counts.values()\n",
    "    return (num_unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 \n",
    "\n",
    "In this case study, we will find and visualize summary statistics of the text of different translations of Hamlet. For this case study, functions `count_words_fast`, `read_book`, and `word_stats` are already defined as in the Case 2 Videos (Videos 3.2.x).\n",
    "\n",
    "#### Instructions \n",
    "- Read in the data as a pandas dataframe using `pd.read_csv`. The data can be found at https://courses.edx.org/asset-v1:HarvardX+PH526x+2T2019+type@asset+block@hamlets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     language                                               text\n",
      "1     English  The Tragedie of Hamlet\\n                      ...\n",
      "2      German  Hamlet, Prinz von DÃ¤nnemark.\\n                ...\n",
      "3  Portuguese  HAMLET\\n                             DRAMA EM ...\n"
     ]
    }
   ],
   "source": [
    "hamlets = pd.read_csv('https://courses.edx.org/asset-v1:HarvardX+PH526x+2T2019+type@asset+block@hamlets.csv', index_col=[0])\n",
    "print (hamlets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 \n",
    "\n",
    "In this exercise, we will summarize the text for a single translation of Hamlet in a `pandas` dataframe. \n",
    "\n",
    "#### Instructions\n",
    "- Find the dictionary of word frequency in `text` by calling `count_words_fast()`. Store this as `counted_text`.\n",
    "- Create a `pandas` dataframe named `data`.\n",
    "- Using `counted_text`, define two columns in data:\n",
    "    - `word`, consisting of each unique word in text.\n",
    "    - `count`, consisting of the number of times each word in `word` is included in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              word  count\n",
      "0              the    935\n",
      "1         tragedie      3\n",
      "2               of    576\n",
      "3           hamlet     97\n",
      "4                   45513\n",
      "...            ...    ...\n",
      "5108  shooteexeunt      1\n",
      "5109      marching      1\n",
      "5110         peale      1\n",
      "5111           ord      1\n",
      "5112         finis      1\n",
      "\n",
      "[5113 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "language, text = hamlets.iloc[0]\n",
    "counted_text = count_words_fast(text)\n",
    "data=pd.DataFrame.from_dict(counted_text, orient='index').reset_index()\n",
    "data=data.rename(columns={'index':'word',0:'count'})\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "In this exercise, we will continue to define summary statistics for a single translation of Hamlet. \n",
    "\n",
    "#### Instructions\n",
    "- Add a column to data named `length`, defined as the length of each word.\n",
    "- Add another column named `frequency`, which is defined as follows for each word in `data`:\n",
    "    - If `count > 10`, `frequency` is \"frequent\".\n",
    "    - If `1 < count <= 10`, `frequency` is \"infrequent\".\n",
    "    - If `count == 1`, `frequency` is \"unique\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3348\n"
     ]
    }
   ],
   "source": [
    "data['length'] = [len(word)for word in data['word']]\n",
    "data['frequency'] = ['frequent' if count > 10 else 'infrequent' if 1 < count <= 10 else 'unique' for count in data['count']]\n",
    "\n",
    "print ((data['frequency'].value_counts())['unique'])#exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "In this exercise, we will summarize the statistics in data into a smaller pandas dataframe. \n",
    "\n",
    "#### Instructions \n",
    "- Create a `pandas` dataframe named `sub_data` including the following columns:\n",
    "    - `language`, which is the language of the text.\n",
    "    - `frequency`, which is a list containing the strings \"frequent\", \"infrequent\", and \"unique\".\n",
    "    - `mean_word_length`, which is the mean word length of each value in frequency.\n",
    "    - `num_words`, which is the total number of words in each frequency category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  language   frequency  mean_word_length  num_words\n",
      "0  English    frequent          4.371517        323\n",
      "1  English  infrequent          5.825243       1442\n",
      "2  English      unique          7.005675       3348\n"
     ]
    }
   ],
   "source": [
    "sub_data= pd.DataFrame(columns =('language','frequency','mean_word_length','num_words'))\n",
    "frequences = ['frequent','infrequent', 'unique']\n",
    "sub_data['frequency'] = frequences\n",
    "sub_data['language'] = language\n",
    "sub_data['mean_word_length']= [(sum((data[data.frequency ==freq])['length'])/len(data[data.frequency ==freq])) for freq in frequences]\n",
    "sub_data['num_words'] =[len(data[data.frequency ==freq]) for freq in frequences]\n",
    "\n",
    "print (sub_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "In this exercise, we will join all the data summaries for text Hamlet translation.\n",
    "\n",
    "#### Instructions \n",
    "- The previous code for summarizing a particular translation of Hamlet is consolidated into a single function called `summarize_text`. Create a pandas dataframe` grouped_data` consisting of the results of `summarize_text` for each translation of Hamlet in `hamlets`.\n",
    "    - Use a `for` loop across the row indices of `hamlets` to assign each translation to a new row.\n",
    "    - Obtain the `ith` row of `hamlets` to variables using the `.iloc` method, and assign the output to variables `language` and `text`.\n",
    "    - Call `summarize_text` using `language` and `text`, and assign the output to `sub_data`.\n",
    "    - Use the pandas `.append()` function to append to pandas dataframes row-wise to `grouped_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(language, text):\n",
    "    counted_text = count_words_fast(text)\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        \"word\": list(counted_text.keys()),\n",
    "        \"count\": list(counted_text.values())\n",
    "    })\n",
    "    \n",
    "    data.loc[data[\"count\"] > 10,  \"frequency\"] = \"frequent\"\n",
    "    data.loc[data[\"count\"] <= 10, \"frequency\"] = \"infrequent\"\n",
    "    data.loc[data[\"count\"] == 1,  \"frequency\"] = \"unique\"\n",
    "    \n",
    "    data[\"length\"] = data[\"word\"].apply(len)\n",
    "    \n",
    "    sub_data = pd.DataFrame({\n",
    "        \"language\": language,\n",
    "        \"frequency\": [\"frequent\",\"infrequent\",\"unique\"],\n",
    "        \"mean_word_length\": data.groupby(by = \"frequency\")[\"length\"].mean(),\n",
    "        \"num_words\": data.groupby(by = \"frequency\").size()\n",
    "    })\n",
    "    \n",
    "    return(sub_data)\n",
    "    \n",
    "# write your code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "In this exercise, we will plot our results and look for differences across each translation.\n",
    "\n",
    "#### Instructions \n",
    "- Plot the word statistics of each translations on a single plot. Note that we have already done most of the work for you.\n",
    "- Consider: do the word statistics differ by translation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"Portuguese\": \"green\", \"English\": \"blue\", \"German\": \"red\"}\n",
    "markers = {\"frequent\": \"o\",\"infrequent\": \"s\", \"unique\": \"^\"}\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(grouped_data.shape[0]):\n",
    "    row = grouped_data.iloc[i]\n",
    "    plt.plot(row.mean_word_length, row.num_words,\n",
    "        marker=markers[row.frequency],\n",
    "        color = colors[row.language],\n",
    "        markersize = 10\n",
    "    )\n",
    "\n",
    "color_legend = []\n",
    "marker_legend = []\n",
    "for color in colors:\n",
    "    color_legend.append(\n",
    "        plt.plot([], [],\n",
    "        color=colors[color],\n",
    "        marker=\"o\",\n",
    "        label = color, markersize = 10, linestyle=\"None\")\n",
    "    )\n",
    "for marker in markers:\n",
    "    marker_legend.append(\n",
    "        plt.plot([], [],\n",
    "        color=\"k\",\n",
    "        marker=markers[marker],\n",
    "        label = marker, markersize = 10, linestyle=\"None\")\n",
    "    )\n",
    "plt.legend(numpoints=1, loc = \"upper left\")\n",
    "\n",
    "plt.xlabel(\"Mean Word Length\")\n",
    "plt.ylabel(\"Number of Words\")\n",
    "# write your code to display the plot here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
